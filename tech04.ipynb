{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de quadros: 3326\n",
      "Rostos detectados: 1177\n",
      "Anomalias na detecção de rostos: 0\n",
      "Emoções detectadas:\n",
      "fear: 137\n",
      "surprise: 179\n",
      "sad: 76\n",
      "happy: 527\n",
      "neutral: 247\n",
      "angry: 11\n",
      "Atividades detectadas:\n",
      "standing: 71\n",
      "sitting: 1118\n",
      "dancing: 0\n",
      "laying: 0\n",
      "Anomalias na detecção de atividades: 2137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import mediapipe as mp\n",
    "\n",
    "# Carregar o Classificador Haar Cascade para detecção de rostos\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Inicializar MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "# Inicializar variáveis para rastrear informações\n",
    "frame_count = 0\n",
    "face_count = 0\n",
    "emotion_count = {}\n",
    "activity_count = {'standing': 0, 'sitting': 0, 'dancing': 0, 'laying': 0}\n",
    "\n",
    "# Inicializar contadores de anomalia\n",
    "face_anomaly_count = 0\n",
    "activity_anomaly_count = 0\n",
    "\n",
    "# Carregar vídeo\n",
    "cap = cv2.VideoCapture('video_analise.mp4')\n",
    "\n",
    "# Definir codec e criar objeto VideoWriter para o vídeo de saída\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output_video.mp4', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "# Função para determinar atividade com base nos pontos de referência da pose\n",
    "def determine_activity(results):\n",
    "    if results.pose_landmarks:\n",
    "        left_shoulder = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "        left_hip = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP]\n",
    "        \n",
    "        if left_shoulder.visibility > 0.5 and left_hip.visibility > 0.5:\n",
    "            shoulder_y = left_shoulder.y\n",
    "            hip_y = left_hip.y\n",
    "            # Determinar se está sentado ou em pé com base nas coordenadas Y\n",
    "            if hip_y > shoulder_y:\n",
    "                return 'sitting'\n",
    "            else:\n",
    "                return 'standing'\n",
    "    return 'unknown'\n",
    "\n",
    "# Iterar por cada quadro do vídeo\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    front_faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    for (x, y, w, h) in front_faces:\n",
    "        # Analisar emoção na região do rosto detectada\n",
    "        face_image = frame[y:y + h, x:x + w]\n",
    "        \n",
    "        try:\n",
    "            analysis = DeepFace.analyze(face_image, actions=['emotion'], enforce_detection=False)\n",
    "            if analysis and isinstance(analysis, list) and len(analysis) > 0:\n",
    "                dominant_emotion = analysis[0]['dominant_emotion']\n",
    "                emotion_count.setdefault(dominant_emotion, 0)\n",
    "                emotion_count[dominant_emotion] += 1\n",
    "                face_count += 1\n",
    "            else:\n",
    "                face_anomaly_count += 1  # Incrementar contagem de anomalias se não houver análise válida\n",
    "        except Exception as e:\n",
    "            print(f\"Erro na detecção de emoção: {e}\")\n",
    "            face_anomaly_count += 1  # Incrementar contagem de anomalias em caso de erro\n",
    "\n",
    "        # Desenhar retângulo e colocar texto para a emoção\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, dominant_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "\n",
    "    # Analisar pose para detecção de atividade\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(image_rgb)\n",
    "\n",
    "    # Determinar atividade com base nos pontos de referência da pose\n",
    "    activity = determine_activity(results)\n",
    "    if activity != 'unknown':\n",
    "        activity_count[activity] += 1\n",
    "    else:\n",
    "        activity_anomaly_count += 1  # Incrementar contagem de anomalias para detecção de atividade\n",
    "\n",
    "    # Escrever atividade no vídeo\n",
    "    cv2.putText(frame, activity, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "    # Escrever o quadro no vídeo de saída\n",
    "    out.write(frame)\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# Imprimir e salvar relatório de análise\n",
    "report = (\n",
    "    f\"Total de quadros: {frame_count}\\n\"\n",
    "    f\"Rostos detectados: {face_count}\\n\"\n",
    "    f\"Anomalias na detecção de rostos: {face_anomaly_count}\\n\"\n",
    "    f\"Emoções detectadas:\\n\" +\n",
    "    ''.join([f\"{emotion}: {count}\\n\" for emotion, count in emotion_count.items()]) +\n",
    "    f\"Atividades detectadas:\\n\" +\n",
    "    ''.join([f\"{activity}: {count}\\n\" for activity, count in activity_count.items()]) +\n",
    "    f\"Anomalias na detecção de atividades: {activity_anomaly_count}\\n\"\n",
    ")\n",
    "\n",
    "# Imprimir o relatório no console\n",
    "print(report)\n",
    "\n",
    "# Escrever o relatório em um arquivo de texto\n",
    "with open('analysis_report.txt', 'w') as f:\n",
    "    f.write(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
